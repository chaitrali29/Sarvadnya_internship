# üß† Ask Vichar-Chitre Chatbot

**‡§Æ‡§æ‡§®‡§∏‡§ø‡§ï ‡§Æ‡•â‡§°‡•á‡§≤‡•ç‡§∏‡§µ‡§∞ ‡§Ü‡§ß‡§æ‡§∞‡§ø‡§§ ‡§Æ‡§∞‡§æ‡§†‡•Ä ‡§ö‡•Ö‡§ü‡§¨‡•â‡§ü**

A sophisticated AI chatbot specialized in Mental Models, built with Retrieval Augmented Generation (RAG) and fine-tuning capabilities. The chatbot can understand and respond to questions about cognitive biases, decision-making frameworks, and thinking patterns in Marathi language.

## üåü Features

- **üîç RAG-powered responses**: Uses LlamaIndex and ChromaDB for intelligent document retrieval
- **üéØ Fine-tuning support**: LoRA-based fine-tuning using Unsloth for specialized responses
- **üáÆüá≥ Multilingual support**: Primarily designed for Marathi with English fallback
- **üöÄ High-performance**: Optimized with Groq API for fast inference
- **üíª User-friendly UI**: Clean Streamlit interface with model selection
- **üìä Vector database**: Persistent ChromaDB storage for efficient retrieval

## üèóÔ∏è Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Streamlit UI  ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   RAG System     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Groq/Gemma API ‚îÇ
‚îÇ   (app.py)      ‚îÇ    ‚îÇ   (rag.py)       ‚îÇ    ‚îÇ                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                       
         ‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Fine-tuner      ‚îÇ              
                        ‚îÇ  (fine_tune.py)  ‚îÇ              
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              
                                 ‚îÇ                        
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              
                        ‚îÇ   ChromaDB       ‚îÇ              
                        ‚îÇ   Vector Store   ‚îÇ              
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              
```

## üöÄ Quick Start

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended for fine-tuning)
- Groq API key ([Get it here](https://console.groq.com/))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/your-username/ask-vichar-chitre-chatbot.git
   cd ask-vichar-chitre-chatbot
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   # Create .env file
   echo "GROQ_API_KEY=your_groq_api_key_here" > .env
   ```

4. **Prepare your data**
   Create text files with mental models descriptions in Marathi and place them in a `data/` directory.

5. **Run the application**
   ```bash
   streamlit run app.py
   ```

### Sample Data Format

Create text files with mental models in this format:

```
Confirmation Bias (‡§™‡•Å‡§∑‡•ç‡§ü‡•Ä‡§ï‡§∞‡§£ ‡§™‡•Ç‡§∞‡•ç‡§µ‡§æ‡§ó‡•ç‡§∞‡§π)

‡§µ‡•ç‡§Ø‡§æ‡§ñ‡•ç‡§Ø‡§æ: ‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§Ü‡§ß‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§µ‡§ø‡§∂‡•ç‡§µ‡§æ‡§∏‡§æ‡§Ç‡§®‡§æ ‡§¨‡§≥‡§ï‡§ü‡•Ä ‡§¶‡•á‡§£‡§æ‡§∞‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§∂‡•ã‡§ß‡§£‡•á ‡§Ü‡§£‡§ø ‡§µ‡§ø‡§∞‡•ã‡§ß‡•Ä ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä‡§ï‡§°‡•á ‡§¶‡•Å‡§∞‡•ç‡§≤‡§ï‡•ç‡§∑ ‡§ï‡§∞‡§£‡•á.

‡§â‡§¶‡§æ‡§π‡§∞‡§£‡•á:
1. ‡§∞‡§æ‡§ú‡§ï‡•Ä‡§Ø ‡§Æ‡§§‡•á: ‡§´‡§ï‡•ç‡§§ ‡§§‡•ç‡§Ø‡§æ‡§ö ‡§®‡•ç‡§Ø‡•Ç‡§ú ‡§ö‡•Ö‡§®‡•á‡§≤ ‡§¨‡§ò‡§£‡•á ‡§ú‡•ç‡§Ø‡§æ ‡§Ü‡§™‡§≤‡•ç‡§Ø‡§æ ‡§∞‡§æ‡§ú‡§ï‡•Ä‡§Ø ‡§™‡§ï‡•ç‡§∑‡§æ‡§≤‡§æ ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§¶‡•á‡§§‡§æ‡§§
2. ‡§ó‡•Å‡§Ç‡§§‡§µ‡§£‡•Ç‡§ï: ‡§è‡§ñ‡§æ‡§¶‡•ç‡§Ø‡§æ ‡§ï‡§Ç‡§™‡§®‡•Ä‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•á ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§Ö‡§∏‡§≤‡•ç‡§Ø‡§æ‡§∏ ‡§´‡§ï‡•ç‡§§ ‡§§‡•ç‡§Ø‡§æ ‡§ï‡§Ç‡§™‡§®‡•Ä‡§ö‡•ç‡§Ø‡§æ ‡§ö‡§æ‡§Ç‡§ó‡§≤‡•ç‡§Ø‡§æ ‡§¨‡§æ‡§§‡§Æ‡•ç‡§Ø‡§æ ‡§µ‡§æ‡§ö‡§£‡•á

‡§ü‡§æ‡§≥‡§£‡•ç‡§Ø‡§æ‡§ö‡•á ‡§Æ‡§æ‡§∞‡•ç‡§ó:
- ‡§µ‡§ø‡§∞‡•ã‡§ß‡•Ä ‡§Æ‡§§‡§æ‡§Ç‡§®‡§æ ‡§¶‡•á‡§ñ‡•Ä‡§≤ ‡§Æ‡§π‡§§‡•ç‡§§‡•ç‡§µ ‡§¶‡•ç‡§Ø‡§æ
- ‡§µ‡§ø‡§µ‡§ø‡§ß ‡§∏‡•ç‡§∞‡•ã‡§§‡§æ‡§Ç‡§ï‡§°‡•Ç‡§® ‡§Æ‡§æ‡§π‡§ø‡§§‡•Ä ‡§ò‡•ç‡§Ø‡§æ
```

## üìö Usage

### Basic RAG Chatbot

```python
from rag import RAGChatbot

# Initialize chatbot
chatbot = RAGChatbot(
    data_directory="./data",
    groq_api_key="your_api_key"
)

# Ask questions in Marathi
response = chatbot.get_response("Sunk cost fallacy ‡§Ø‡§æ mental model ‡§≤‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§ï‡§æ‡§Ø ‡§Æ‡•ç‡§π‡§£‡§æ‡§§‡§æ‡§§?")
print(response)
```

### Fine-tuning

```python
from fine_tune import FineTuner

# Initialize fine-tuner
fine_tuner = FineTuner(data_directory="./data")

# Prepare data and fine-tune
fine_tuner.prepare_training_data()
fine_tuner.fine_tune_model(output_dir="./fine_tuned_model")

# Generate responses with fine-tuned model
response = fine_tuner.generate_response("Anchoring bias ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§∏‡§æ‡§Ç‡§ó‡§æ")
```

## üéØ Example Questions

- `Sunk cost fallacy ‡§Ø‡§æ mental model ‡§≤‡§æ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§ï‡§æ‡§Ø ‡§Æ‡•ç‡§π‡§£‡§æ‡§§‡§æ‡§§ ‡§Ü‡§£‡§ø ‡§§‡•ç‡§Ø‡§æ‡§ö‡•á ‡§â‡§¶‡§æ‡§π‡§∞‡§£ ‡§¶‡•ç‡§Ø‡§æ`
- `Confirmation bias ‡§¨‡§¶‡•ç‡§¶‡§≤ ‡§Æ‡§∞‡§æ‡§†‡•Ä‡§§ ‡§∏‡§æ‡§Ç‡§ó‡§æ`
- `Decision making ‡§Æ‡§ß‡•ç‡§Ø‡•á ‡§ï‡•ã‡§£‡§§‡•á mental models ‡§µ‡§æ‡§™‡§∞‡§æ‡§µ‡•á?`
- `Anchoring bias ‡§Æ‡•ç‡§π‡§£‡§ú‡•á ‡§ï‡§æ‡§Ø ‡§Ü‡§£‡§ø ‡§§‡•á ‡§ï‡§∏‡•á ‡§ü‡§æ‡§≥‡§æ‡§µ‡•á?`

## üîß Configuration

### Model Settings

- **Base Model**: `google/gemma-7b-it`
- **Embedding Model**: `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2`
- **Vector Store**: ChromaDB with persistent storage
- **Fine-tuning**: LoRA with rank 16, alpha 16

### Customization

You can modify these settings in the respective classes:

```python
# In rag.py
chatbot = RAGChatbot(
    model_name="google/gemma-7b-it",  # Change model
    embedding_model="your-embedding-model"  # Change embeddings
)

# In fine_tune.py
fine_tuner = FineTuner(
    model_name="google/gemma-7b-it",  # Base model for fine-tuning
    max_seq_length=2048  # Adjust sequence length
)
```

## üß™ Testing

Each module includes comprehensive tests:

```bash
# Test RAG functionality
python rag_module.py

# Test fine-tuning (requires GPU)
python finetune_module.py

# Run the full application
streamlit run streamlit_app.py
```

## üìÅ Project Structure

```
ask-vichar-chitre-chatbot/
‚îú‚îÄ‚îÄ streamlit_app.py    # Streamlit UI application
‚îú‚îÄ‚îÄ rag_module.py       # RAG system implementation
‚îú‚îÄ‚îÄ finetune_module.py  # Fine-tuning functionality
‚îú‚îÄ‚îÄ requirements.txt    # Python dependencies
‚îú‚îÄ‚îÄ README.md          # This file
‚îú‚îÄ‚îÄ .env               # Environment variables (create this)
‚îú‚îÄ‚îÄ data/              # Your mental models data (create this)
‚îú‚îÄ


## References
- [MarathiNLP: l3cube-pune: ](https://github.com/l3cube-pune/MarathiNLP), datasets, models etc